{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def search(keywords, csv_file: pd.DataFrame, columns=None):\n",
    "    if not columns:\n",
    "        columns = [\"Testcase\", \"Crash\", \"Health\", \"Consistency\"]\n",
    "\n",
    "    results = csv_file.copy()\n",
    "    for keyword in keywords:\n",
    "        mask = results[columns].apply(lambda x: x.str.contains(keyword, case=False, na=False)).any(axis=1)\n",
    "        results = results[mask]\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resources.limits 25\n",
      "ingress.annotations 21\n",
      "resources.requests 21\n",
      "resourceFieldRef.divisor 16\n",
      "route.annotations 13\n",
      "route.labels 12\n",
      "ingress.tls 11\n",
      "server.extraCommandArgs 5\n",
      "controller.env 3\n",
      "notifications.env 2\n",
      "grafana.version 2\n",
      "server.env 2\n",
      "grafana.image 2\n",
      "ha.redisProxyImage 2\n",
      "repo.env 2\n",
      "applicationSet.image 2\n",
      "ha.redisProxyVersion 2\n",
      "tls.initialCerts 2\n",
      "image 2\n",
      "applicationSet.env 2\n",
      "repo.volumes 2\n",
      "nodePlacement.tolerations 1\n",
      "secretKeyRef.name 1\n",
      "controller.resources 1\n",
      "sidecarContainers.restartPolicy 1\n",
      "initContainers.imagePullPolicy 1\n",
      "fieldRef.apiVersion 1\n",
      "monitoring.enabled 1\n",
      "sharding.replicas 1\n",
      "initContainers.restartPolicy 1\n",
      "resizePolicy.restartPolicy 1\n",
      "notifications.replicas 1\n",
      "spec.accessModes 1\n",
      "server.replicas 1\n",
      "repo.replicas 1\n",
      "sidecarContainers.imagePullPolicy 1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "# {\"field\": \"[\\\"spec\\\", \\\"notifications\\\", \\\"env\\\"]\", \"testcase\": \"array-pop\"}\n",
    "# The \"Testcase\" column has messages like the above. I want to extract the array associated with the \"field\" key.\n",
    "# From the array, I want to look at the elements from the end. I want to group all rows that have the same last 2 elements in that array\n",
    "\n",
    "# For each row\n",
    "def get_testcase_groups(df):\n",
    "  testcase_groups = {}\n",
    "  for index, full_row in df.iterrows():\n",
    "    row = full_row[\"Testcase\"]\n",
    "    if row == \"{}\":\n",
    "      continue\n",
    "    fields = json.loads(json.loads(row)[\"field\"])\n",
    "    testcase = json.loads(row)[\"testcase\"]\n",
    "    if testcase == \"object-deletion\":\n",
    "      # This focuses on the Consistency oracle when the testcase is \"object-deletion\"\n",
    "      path = re.search(r'path=\\[(.*?)\\]', full_row[\"Consistency\"]).group(1)\n",
    "      fields = json.loads(f\"[{path}]\")\n",
    "    last_2_elements = []\n",
    "    count = 0\n",
    "    for i in range(-1, -len(fields), -1):\n",
    "      if count == 2:\n",
    "        break\n",
    "      if fields[i] == \"ACTOKEY\" or fields[i] == 0:\n",
    "        continue\n",
    "      last_2_elements.append(fields[i])\n",
    "      count += 1\n",
    "    group = \".\".join(last_2_elements[::-1])\n",
    "    if group in testcase_groups:\n",
    "      testcase_groups[group].append(full_row)\n",
    "    else:\n",
    "      testcase_groups[group] = [full_row]\n",
    "  return testcase_groups\n",
    "      \n",
    "    \n",
    "testcase_groups = get_testcase_groups(alarms)\n",
    "sorted_groups = sorted(testcase_groups, key=lambda x: len(testcase_groups[x]), reverse=True)\n",
    "\n",
    "for group in sorted_groups:\n",
    "  print(group, len(testcase_groups[group]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`trial-01-0004/0002`\n",
      "`trial-01-0066/0004`\n",
      "`trial-03-0012/0002`\n",
      "`trial-03-0021/0001`\n",
      "`trial-04-0024/0005`\n",
      "`trial-04-0048/0006`\n",
      "`trial-04-0056/0004`\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "s = []\n",
    "for i in testcase_groups[\"ingress.annotations\"]:\n",
    "  # print(count, i[\"Testcase\"])\n",
    "  if \"annotations\" not in i[\"Testcase\"]:\n",
    "    s.append(f\"`{i['Trial number'][25:]}`\")\n",
    "    # continue\n",
    "  # print(count, i[\"Testcase\"])\n",
    "  count += 1\n",
    "\n",
    "print(\"\\n\".join(s))\n",
    "# print(testcase_groups[\"ingress.annotations\"][8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'trial-00-0028/0008', 'trial-00-0029/0001', 'trial-00-0030/0001', 'trial-00-0040/0008', 'trial-01-0067/0002', 'trial-01-0070/0003', 'trial-02-0009/0002', 'trial-02-0016/0002', 'trial-02-0017/0001', 'trial-03-0020/0001', 'trial-03-0024/0005', 'trial-03-0025/0003', 'trial-04-0047/0002', 'trial-00-0002/0002', 'trial-00-0007/0003', 'trial-00-0036/0005', 'trial-01-0001/0007', 'trial-01-0002/0003', 'trial-01-0004/0002', 'trial-01-0066/0004', 'trial-02-0000/0003', 'trial-03-0012/0002', 'trial-03-0021/0001', 'trial-03-0027/0010', 'trial-03-0028/0003', 'trial-03-0045/0009', 'trial-03-0068/0005', 'trial-03-0070/0009', 'trial-03-0071/0003', 'trial-04-0024/0005', 'trial-04-0042/0003', 'trial-04-0043/0003', 'trial-04-0048/0006', 'trial-04-0056/0004', "
     ]
    }
   ],
   "source": [
    "results = pd.read_csv(\"results.csv\")\n",
    "alarms = results[results[\"Alarm\"] == True]\n",
    "if alarms[\"Testcase\"].str.contains(\"trial-01-0004/0002\", case=False, na=False).any():\n",
    "  print(\"Found\")\n",
    "\n",
    "keywords = [\"ingress\", \"annotations\"]\n",
    "columns = None\n",
    "ingress_annotations = search(keywords=keywords, columns=columns, csv_file=alarms)\n",
    "\n",
    "keywords = [\"route\", \"annotations\"]\n",
    "route_annotations = search(keywords=keywords, csv_file=alarms)\n",
    "\n",
    "for i in route_annotations[\"Trial number\"].str.extract('(trial.*)', expand=False):\n",
    "  print(f\"'{i}', \", end=\"\")\n",
    "for i in ingress_annotations[\"Trial number\"].str.extract('(trial.*)', expand=False):\n",
    "  print(f\"'{i}', \", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-n-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
